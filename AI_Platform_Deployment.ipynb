{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Platform_Deployment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUciUyuzEjfQzn91FCyMri"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toKdM7dacl47"
      },
      "source": [
        "# Authentications\n",
        "First, let's authenticate the colab notebook to access both GCP and GEE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Pix_tTekfA"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEl8TOT9ep77"
      },
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTpbPty_doo0"
      },
      "source": [
        "# Imports\n",
        "Note that we downgraded tensorflow to `2.1.0`. That's because that's the tensorflow runtime version  that we use to train, eeify, and deploy the model later on. So we want to make sure that this colab notebook is using the same version.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOTS1O9S_gcw"
      },
      "source": [
        "!pip install tensorflow==2.1.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8lkli0O_4Qc"
      },
      "source": [
        "import folium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFe0yL1khCu8"
      },
      "source": [
        "# Config Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLVNseHj4Y7o"
      },
      "source": [
        "# INSERT YOUR PROJECT HERE!\n",
        "PROJECT = 'GCP project Id'\n",
        "\n",
        "# INSERT YOUR BUCKET HERE!\n",
        "BUCKET = 'your bucket'\n",
        "\n",
        "# Specify names of output locations in Cloud Storage.\n",
        "JOB_FOLDER = 'your folder'\n",
        "JOB_DIR = 'gs://' + BUCKET + '/' + JOB_FOLDER + '/trainer'\n",
        "MODEL_DIR = JOB_DIR + '/model'\n",
        "LOGS_DIR = JOB_DIR + '/logs'\n",
        "\n",
        "# Put the EEified model next to the trained model directory.\n",
        "EEIFIED_DIR = JOB_DIR + '/eeified'\n",
        "\n",
        "# Pre-computed training and eval data.\n",
        "DATA_BUCKET = 'bucket from data prep notebook'\n",
        "FOLDER = 'FOLDER from data prep notebook'\n",
        "TRAINING_BASE = 'training_patches'\n",
        "EVAL_BASE = 'eval_patches'\n",
        "\n",
        "# Specify inputs (Landsat bands) to the model and the response variable.\n",
        "opticalBands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "thermalBands = ['B10', 'B11']\n",
        "BANDS = opticalBands + thermalBands\n",
        "RESPONSE = 'cultivated'\n",
        "FEATURES = BANDS + [RESPONSE]\n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "KERNEL_SIZE = 256\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
        "\n",
        "# Sizes of the training and evaluation datasets.\n",
        "TRAIN_SIZE = 16000\n",
        "EVAL_SIZE = 8000\n",
        "\n",
        "# Specify model training parameters.\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "BUFFER_SIZE = 3000\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = ['binary_accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i_C7PpOfW5j"
      },
      "source": [
        "# EEification of the Model\n",
        "Before we can host the model on AI Platform we need to EEify it. The EEification process appends some extra operations to the input and outputs of the model in order to accomdate the interchange format between pixels from Earth Engine (float32) and inputs to AI Platform (base64). (See https://cloud.google.com/ai-platform/prediction/docs/online-predict#binary_data_in_prediction_input for details.)\n",
        "\n",
        "The EEification process is handled for you using the Earth Engine command `earthengine model prepare`. To use that command, we need to specify the input and output model directories and the name of the input and output nodes in the TensorFlow computation graph. We can do all that programmatically:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJXTtL0agcW8"
      },
      "source": [
        "from tensorflow.python.tools import saved_model_utils\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(MODEL_DIR, 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "  input_name = v.name\n",
        "  break\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "  output_name = v.name\n",
        "  break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to \n",
        "# AI Platform inputs and outputs, respectively.\n",
        "import json\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: \"impervious\"}) + \"'\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp9tuqPygtEH"
      },
      "source": [
        "The project needs to be set  before using the model prepare command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi5IoEn_g6T2"
      },
      "source": [
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {MODEL_DIR} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN7z0IwrjzQL"
      },
      "source": [
        "# Model Deployment\n",
        "I personally prefer doing this via AI Platforms model console but it can be done via command line as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtoowd5XkUyA"
      },
      "source": [
        "%%writefile config.yaml\n",
        "autoScaling:\n",
        "    minNodes: 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSp34aCaySu5"
      },
      "source": [
        "MODEL_NAME = 'model_name'\n",
        "VERSION_NAME = 'version_name' \n",
        "REGION = 'region_name'\n",
        "\n",
        "!gcloud ai-platform models create {MODEL_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION}\n",
        "\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --region {REGION} \\\n",
        "  --origin {EEIFIED_DIR} \\\n",
        "  --framework \"TENSORFLOW\" \\\n",
        "  --runtime-version 2.1 \\\n",
        "  --python-version 3.7 \\\n",
        "  --config=config.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1B9UNDXleRO"
      },
      "source": [
        "# Inference using the deployed model\n",
        "Earth Engine can directly be connected to the trained model for inference using `ee.Model.fromAiPlatformPredictor` command. To connect to the model, we need to know the name and version.\n",
        "\n",
        "### Inputs\n",
        "we need to be able to recreate the imagery on which it was trained in order to perform inference.  Specifically, we need to create an array-valued input from the scaled data and use that for input.  (Recall that the new input node is named `array`, which is convenient because the array image has one band, named `array` by default.)  The inputs will be provided as 144x144 patches (`inputTileSize`), at 30-meter resolution (`proj`), but 8 pixels will be thrown out (`inputOverlapSize`) to minimize boundary effects.\n",
        "\n",
        "### Outputs\n",
        "The output (which we also need to know), is a single float band named `cultivated`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY-Dp69ommZK"
      },
      "source": [
        "# Cloud masking function.\n",
        "def maskL8sr(image):\n",
        "  cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
        "  cloudsBitMask = ee.Number(2).pow(5).int()\n",
        "  qa = image.select('pixel_qa')\n",
        "  mask1 = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
        "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
        "  mask2 = image.mask().reduce('min')\n",
        "  mask3 = image.select(config.opticalBands).gt(0).And(\n",
        "          image.select(config.opticalBands).lt(10000)).reduce('min')\n",
        "  mask = mask1.And(mask2).And(mask3)\n",
        "  return image.select(config.opticalBands).divide(10000).addBands(\n",
        "          image.select(config.thermalBands).divide(10).clamp(273.15, 373.15)\n",
        "            .subtract(273.15).divide(100)).updateMask(mask)\n",
        "\n",
        "# The image input data is a cloud-masked median composite.\n",
        "image = l8sr.filterDate(\n",
        "    '2015-01-01', '2017-12-31').map(maskL8sr).median().select(config.BANDS).float()\n",
        "\n",
        "# Load the trained model and use it for prediction.\n",
        "model = ee.Model.fromAiPlatformPredictor(\n",
        "    projectName = PROJECT,\n",
        "    modelName = MODEL_NAME,\n",
        "    version = VERSION_NAME,\n",
        "    inputTileSize = [144, 144],\n",
        "    inputOverlapSize = [8, 8],\n",
        "    proj = ee.Projection('EPSG:4326').atScale(30),\n",
        "    fixInputProj = True,\n",
        "    outputBands = {'cultivated': {\n",
        "        'type': ee.PixelType.float()\n",
        "      }\n",
        "    }\n",
        ")\n",
        "\n",
        "predictions = model.predictImage(image.toArray())\n",
        "# Use folium to visualize the input imagery and the predictions.\n",
        "mapid = image.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3})\n",
        "map = folium.Map(location=[36.71, -120.55], zoom_start=20)\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Google Earth Engine',\n",
        "    overlay=True,\n",
        "    name='median composite',\n",
        "  ).add_to(map)\n",
        "mapid = predictions.getMapId({'min': 0, 'max': 1})\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Google Earth Engine',\n",
        "    overlay=True,\n",
        "    name='cultivated',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}